{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install yfinance\n","!pip install transformers\n","!pip install datasets\n","!pip install accelerate\n","!pip install faiss-cpu\n","!pip install py2neo"],"metadata":{"id":"MJ7YDxq-A72p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yfinance as yf\n","import random\n","import json\n","\n","# Company Codes\n","company_tickers = [\n","    \"AAPL\", \"TSLA\", \"GOOGL\", \"AMZN\", \"MSFT\", \"FB\", \"NFLX\", \"NVDA\", \"INTC\", \"AMD\",\n","    \"BABA\", \"BA\", \"WMT\", \"PFE\", \"MRNA\", \"JPM\", \"GS\", \"V\", \"MA\", \"PYPL\",\n","    \"KO\", \"PEP\", \"XOM\", \"CVX\", \"SPCE\", \"UBER\", \"LYFT\", \"TWTR\", \"SHOP\", \"SQ\",\n","    \"T\", \"VZ\", \"IBM\", \"ORCL\", \"CSCO\", \"ADBE\", \"CRM\", \"ZM\", \"DOCU\", \"SNOW\",\n","    \"DIS\", \"SBUX\", \"MCD\", \"NKE\", \"HD\", \"COST\", \"LOW\", \"TGT\", \"WBA\", \"CVS\",\n","    \"TXN\", \"QCOM\", \"MU\", \"AVGO\", \"LRCX\", \"AMD\", \"REGN\", \"GILD\", \"BIIB\", \"MRK\",\n","    \"LLY\", \"ABBV\", \"ABT\", \"BMY\", \"DHR\", \"MDT\", \"ISRG\", \"SYK\", \"BDX\", \"ZTS\",\n","    \"NVS\", \"AZN\", \"SNY\", \"ROG\", \"BIDU\", \"JD\", \"PDD\", \"NTES\", \"TME\", \"BILI\",\n","    \"TSM\", \"SNE\", \"NTDOY\", \"NSRGY\", \"HSBC\", \"RY\", \"TD\", \"BCS\", \"BNS\", \"BBVA\",\n","    \"DB\", \"CS\", \"UBS\", \"JPM\", \"BAC\", \"C\", \"MS\", \"WFC\", \"GS\", \"AXP\"\n","]\n","\n","# Extract financial data\n","def fetch_and_save_financial_data(ticker_list, num_companies=100):\n","    financial_data = []\n","    selected_tickers = random.sample(ticker_list, num_companies)\n","\n","    for ticker in selected_tickers:\n","        print(f\"Fetching financial data for {ticker}...\")\n","        stock = yf.Ticker(ticker)\n","        balance_sheet = stock.balance_sheet\n","\n","        if not balance_sheet.empty:\n","            #  Extract financial data, defaulting to None if missing\n","            try:\n","                total_assets = balance_sheet.loc[\"Total Assets\"].iloc[0]\n","            except KeyError:\n","                total_assets = None\n","                print(f\"Total Assets not found for {ticker}\")\n","\n","            # Checking alternative fields if primary ones are missing\n","            try:\n","                total_liabilities = balance_sheet.loc[\"Total Liabilities\"].iloc[0]\n","            except KeyError:\n","                total_liabilities = balance_sheet.loc[\"Long Term Debt\"].iloc[0] if \"Long Term Debt\" in balance_sheet.index else None\n","                if total_liabilities is None:\n","                    print(f\"Total Liabilities not found for {ticker} (tried alternative fields).\")\n","\n","            try:\n","                total_equity = balance_sheet.loc[\"Total Stockholder Equity\"].iloc[0]\n","            except KeyError:\n","                total_equity = balance_sheet.loc[\"Net Worth\"].iloc[0] if \"Net Worth\" in balance_sheet.index else None\n","                if total_equity is None:\n","                    print(f\"Total Stockholder Equity not found for {ticker} (tried alternative fields).\")\n","\n","            # Converting Timestamp to string for JSON serialization\n","            try:\n","                year = str(balance_sheet.columns[0])  # Convert timestamp to string\n","            except Exception:\n","                year = \"Unknown\"\n","\n","            # Appending if at least one piece of financial data is present\n","            if total_assets is not None or total_liabilities is not None or total_equity is not None:\n","                data = {\n","                    \"ticker\": ticker,\n","                    \"Total Assets\": total_assets,\n","                    \"Total Liabilities\": total_liabilities,\n","                    \"Total Stockholder Equity\": total_equity,\n","                    \"Year\": year  # Year as string to avoid JSON serialization issues\n","                }\n","                financial_data.append(data)\n","        else:\n","            print(f\"No balance sheet data found for {ticker}\")\n","\n","    # Saving the fetched data to a file\n","    with open(\"financial_data_100_companies.json\", \"w\") as f:\n","        json.dump(financial_data, f)\n","\n","    print(\"Financial data for 100 companies saved successfully.\")\n","    return financial_data\n","\n","# Fetch and save financial data\n","financial_data = fetch_and_save_financial_data(company_tickers, num_companies=100)\n"],"metadata":{"id":"rxYvQSLjBIVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating a question-answer dataset using the financial data\n","def prepare_question_answer_dataset(financial_data):\n","    dataset = []\n","\n","    for company in financial_data:\n","        questions = [\n","            f\"What are the total assets of {company['ticker']} in {company['Year']}?\",\n","            f\"What are the total liabilities of {company['ticker']} in {company['Year']}?\",\n","            f\"What is the total shareholder equity of {company['ticker']} in {company['Year']}?\"\n","        ]\n","\n","        answers = [\n","            f\"The total assets of {company['ticker']} in {company['Year']} were {company['Total Assets']} USD.\",\n","            f\"The total liabilities of {company['ticker']} in {company['Year']} were {company['Total Liabilities']} USD.\",\n","            f\"The total shareholder equity of {company['ticker']} in {company['Year']} was {company['Total Stockholder Equity']} USD.\"\n","        ]\n","\n","        for q, a in zip(questions, answers):\n","            dataset.append({\"question\": q, \"answer\": a})\n","\n","    return dataset\n","\n","# Preparing the dataset\n","financial_finetune_dataset = prepare_question_answer_dataset(financial_data)\n","\n","# Saving the dataset as a JSON file\n","with open(\"financial_finetune_dataset.json\", \"w\") as f:\n","    json.dump(financial_finetune_dataset, f)\n","\n","print(\"Financial dataset prepared and saved.\")\n"],"metadata":{"id":"BjiRvbL3BXjc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, DataCollatorForLanguageModeling\n","import torch\n","from datasets import Dataset\n","import json\n","from accelerate import Accelerator\n","\n","# Loading the fine-tuning dataset\n","with open(\"financial_finetune_dataset.json\", \"r\") as f:\n","    financial_data = json.load(f)\n","\n","# Preparing the dataset for Hugging Face's format\n","dataset = Dataset.from_list(financial_data)\n","\n","# Loading tokenizer and model\n","model_name = \"NousResearch/LLaMA-2-7b-hf\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Initializing model with ZeRO-Offload to CPU\n","model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n","\n","# Tokenizing the dataset\n","def tokenize_data(example):\n","    question = example['question']\n","    answer = example['answer']\n","    return tokenizer(\n","        f\"Question: {question} Answer: {answer}\",\n","        truncation=True,\n","        max_length=512,\n","        padding=\"max_length\"\n","    )\n","\n","# Tokenizing the dataset\n","tokenized_dataset = dataset.map(tokenize_data, batched=True, remove_columns=[\"question\", \"answer\"])\n","\n","# Data collator to convert batch to tensors\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","# Initializing Accelerator for memory-efficient training\n","accelerator = Accelerator()\n","\n","# Initializing optimizer\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","# Preparing model, optimizer, and data loaders with Accelerator\n","model, optimizer, tokenized_dataset = accelerator.prepare(model, optimizer, tokenized_dataset)\n","\n","# Training loop\n","for epoch in range(5):\n","    model.train()\n","    for batch in tokenized_dataset:\n","        batch = data_collator([batch])\n","\n","        # Moving batch to the correct device using accelerator\n","        batch = {k: v.to(accelerator.device) for k, v in batch.items()}\n","\n","\n","        print(f\"Input IDs shape: {batch['input_ids'].shape}\")\n","        print(f\"Input IDs: {batch['input_ids']}\")\n","        print(f\"Attention Mask shape: {batch['attention_mask'].shape}\")\n","        print(f\"Attention Mask: {batch['attention_mask']}\")\n","\n","        # Checking if the input has a sufficient sequence length\n","        if len(batch['input_ids'].shape) > 1 and batch['input_ids'].shape[1] > 1:\n","            # Pass the inputs to the model\n","            outputs = model(**batch)\n","            loss = outputs.loss\n","            accelerator.backward(loss)\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        else:\n","            print(f\"Skipping batch with shape: {batch['input_ids'].shape}\")\n","\n","    print(f\"Epoch {epoch + 1} completed.\")\n","\n","# Saving the fine-tuned model\n","accelerator.wait_for_everyone()\n","model.save_pretrained(\"finetuned_llama_model\")\n","tokenizer.save_pretrained(\"finetuned_llama_model\")\n","print(\"Fine-tuned LLaMA model saved.\")\n"],"metadata":{"id":"XaVcWqlaBiUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking the contents of financial_data to see which keys are present\n","print(financial_data[:5])\n","\n","# Preparing financial documents for FAISS, handling missing fields\n","documents = []\n","for company in financial_data:\n","    # Handling missing fields gracefully with defaults\n","    ticker = company.get('ticker', 'Unknown')\n","    total_assets = company.get('Total Assets', 'N/A')\n","    total_liabilities = company.get('Total Liabilities', 'N/A')\n","    shareholder_equity = company.get('Total Stockholder Equity', 'N/A')\n","\n","    document = f\"{ticker} Financials: Total Assets {total_assets}, Total Liabilities {total_liabilities}, Shareholder Equity {shareholder_equity}\"\n","    documents.append(document)\n","\n","index, embedding_model, embedding_tokenizer = setup_faiss(documents)\n"],"metadata":{"id":"ljVoHF3cBrRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preparing financial documents for FAISS based on questions and answers\n","documents = [f\"Question: {entry['question']} Answer: {entry['answer']}\" for entry in financial_data]\n","\n","\n","index, embedding_model, embedding_tokenizer = setup_faiss(documents)\n","\n","print(f\"Total documents indexed: {len(documents)}\")\n"],"metadata":{"id":"Q11DJe8FIbKa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import faiss\n","from transformers import AutoModel, AutoTokenizer\n","\n","#  Querying FAISS index for relevant financial documents based on user query\n","def query_faiss(query, index, embedding_model, embedding_tokenizer, documents, k=3):\n","    # Tokenize and encode the query\n","    encoded_query = embedding_tokenizer([query], return_tensors=\"pt\", padding=True, truncation=True)\n","\n","    # Moving inputs to the same device as the model\n","    encoded_query = {k: v.to(embedding_model.device) for k, v in encoded_query.items()}\n","\n","    # Generating the embedding for the query\n","    with torch.no_grad():\n","        query_embedding = embedding_model(**encoded_query).last_hidden_state.mean(dim=1).cpu().numpy()\n","\n","    # Searching FAISS index to get top-k results\n","    _, indices = index.search(query_embedding, k)\n","\n","    # Retrieving the top-k relevant documents\n","    relevant_docs = [documents[i] for i in indices[0]]\n","\n","    return relevant_docs\n","\n","# Example query\n","user_query = \"What are the total assets of AAPL?\"\n","\n","# Query FAISS to retrieve relevant financial documents\n","relevant_docs = query_faiss(user_query, index, embedding_model, embedding_tokenizer, documents)\n","\n","# Display the results\n","print(\"Relevant Financial Information:\")\n","for i, doc in enumerate(relevant_docs, 1):\n","    print(f\"Result {i}: {doc}\")\n"],"metadata":{"id":"q4HVQYHLItdV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  Adding Neo4j Integration\n","from py2neo import Graph, Node, Relationship\n","\n","graph = Graph(\"neo4j+s://8d1ce1f5.databases.neo4j.io\", auth=(\"neo4j\", \"1kb73GatQB5RE_hfad_pOVdM-F8v3RDbE9PHCYBmGiI\"))\n","\n","def query_neo4j(company_ticker):\n","    query = f\"\"\"\n","    MATCH (c:Company)-[:HAS_FINANCIAL_DATA]->(f:Financials)\n","    WHERE c.name='{company_ticker}'\n","    RETURN f.total_assets, f.total_liabilities, f.shareholder_equity\n","    \"\"\"\n","    result = graph.run(query).data()\n","\n","    if result:\n","        financials = result[0]\n","        return f\"Total Assets: {financials['f.total_assets']}, Total Liabilities: {financials['f.total_liabilities']}, Shareholder Equity: {financials['f.shareholder_equity']}\"\n","    else:\n","        return \"No structured financial data found for this company in Neo4j.\"\n"],"metadata":{"id":"IRc3QIsAJ9A3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Full Pipeline\n","def generate_llm_response(query, retrieved_docs, llama_model, llama_tokenizer):\n","    # Combine the user query with retrieved FAISS documents\n","    context = \"\\n\".join(retrieved_docs)\n","    full_prompt = f\"User question: {query}\\n\\nFinancial Information:\\n{context}\\n\\nAnswer:\"\n","\n","    # Tokenize the input and move it to the GPU\n","    inputs = llama_tokenizer(full_prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","    # Generate a response using the LLaMA model, controlling max_new_tokens\n","    with torch.no_grad():\n","        output = llama_model.generate(**inputs, max_new_tokens=150)\n","\n","    # Decode the generated response\n","    response = llama_tokenizer.decode(output[0], skip_special_tokens=True)\n","    return response\n","\n","\n","def full_pipeline(user_query, faiss_index, embedding_model, embedding_tokenizer, documents, llama_model, llama_tokenizer):\n","    company_ticker = user_query.split()[-1].upper().replace(\"?\", \"\")\n","\n","    neo4j_data = query_neo4j(company_ticker)\n","\n","    if \"No structured financial data\" not in neo4j_data:\n","        return f\"Neo4j Financial Data: {neo4j_data}\"\n","    else:\n","        relevant_docs = query_faiss(user_query, faiss_index, embedding_model, embedding_tokenizer, documents)\n","        final_response = generate_llm_response(user_query, relevant_docs, llama_model, llama_tokenizer)\n","        return f\"FAISS-based Financial Data: {final_response}\"\n"],"metadata":{"id":"6B0qWRevKZ2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_query = \"Should I invest in AAPL?\"\n","\n","# Run the full pipeline\n","final_response = full_pipeline(user_query, index, embedding_model, embedding_tokenizer, documents, model, tokenizer)\n","\n","# Display the final response\n","print(\"Final Response:\")\n","print(final_response)\n"],"metadata":{"id":"95KZBMYeKgqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import yfinance as yf\n","\n","def get_ground_truth(ticker):\n","    stock = yf.Ticker(ticker)\n","    balance_sheet = stock.balance_sheet\n","    if not balance_sheet.empty:\n","        total_assets = balance_sheet.loc[\"Total Assets\"].iloc[0] if \"Total Assets\" in balance_sheet.index else None\n","        total_liabilities = balance_sheet.loc[\"Total Liabilities\"].iloc[0] if \"Total Liabilities\" in balance_sheet.index else None\n","        total_equity = balance_sheet.loc[\"Total Stockholder Equity\"].iloc[0] if \"Total Stockholder Equity\" in balance_sheet.index else None\n","\n","        return {\n","            \"Total Assets\": total_assets,\n","            \"Total Liabilities\": total_liabilities,\n","            \"Total Stockholder Equity\": total_equity\n","        }\n","    return None\n","\n","# Example to generate ground truth for AAPL\n","ground_truth = get_ground_truth(\"AAPL\")\n","print(ground_truth)\n"],"metadata":{"id":"Ru9RHk4UMOic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.translate.bleu_score import sentence_bleu\n","\n","# Example LLaMA-generated response\n","generated_response = \"The total assets of AAPL in 2021 were 350 billion USD.\"\n","\n","# Ground truth retrieved from Yahoo Finance\n","ground_truth = get_ground_truth(\"AAPL\")\n","ground_truth_answer = f\"The total assets of AAPL in 2021 were {ground_truth['Total Assets']} USD.\"\n","\n","#  BLEU score\n","reference = [ground_truth_answer.split()]  # Ground truth answer\n","candidate = generated_response.split()  # Generated response from LLaMA\n","\n","bleu_score = sentence_bleu(reference, candidate)\n","print(f\"BLEU score: {bleu_score}\")\n"],"metadata":{"id":"FWchRPjSMW6W"},"execution_count":null,"outputs":[]}]}